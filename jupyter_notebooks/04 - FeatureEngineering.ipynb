{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Engineer new features from the existing dataset to improve model performance.\n",
        "## Inputs\n",
        "\n",
        "* output/datasets/collection/insurance.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Processed train and test datasets with new features added. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_raw_path = \"outputs/datasets/cleaned/insurance_cleaned.csv\"\n",
        "df = pd.read_csv(df_raw_path)\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will enconde and create new features based on the existing ones to enhance the model's predictive power."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "def prepare_features_for_modeling(df):\n",
        "    \"\"\"\n",
        "    Performs feature engineering, encoding, and scaling for the insurance dataset.\n",
        "    \n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): Raw insurance dataset\n",
        "    \n",
        "    Returns:\n",
        "    - df_processed (pd.DataFrame): Processed DataFrame ready for ML modeling\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Feature Engineering\n",
        "    df['age_squared'] = df['age'] ** 2\n",
        "    df['age_group'] = pd.cut(df['age'], bins=[0, 25, 35, 50, 65],\n",
        "                             labels=['Young', 'Adult', 'Middle-aged', 'Senior'])\n",
        "\n",
        "    df['bmi_class'] = pd.cut(df['bmi'], bins=[0, 18.5, 24.9, 29.9, float('inf')],\n",
        "                             labels=['Underweight', 'Normal', 'Overweight', 'Obese'])\n",
        "    df['is_overweight'] = (df['bmi'] >= 25).astype(int)\n",
        "\n",
        "    df['smoker_flag'] = (df['smoker'] == 'yes').astype(int)\n",
        "    df['smoker_bmi_risk'] = df['smoker_flag'] * df['bmi']\n",
        "    df['age_bmi_risk'] = df['age'] * df['bmi'] / 100\n",
        "\n",
        "    # Risk Score\n",
        "    def calculate_risk_score(row):\n",
        "        score = 0\n",
        "        if row['smoker'] == 'yes':\n",
        "            score += 50\n",
        "        if row['bmi'] >= 30:\n",
        "            score += 30\n",
        "        elif row['bmi'] >= 25:\n",
        "            score += 15\n",
        "        if row['age'] >= 50:\n",
        "            score += 25\n",
        "        elif row['age'] >= 35:\n",
        "            score += 15\n",
        "        score += row['children'] * 5\n",
        "        return score\n",
        "\n",
        "    df['risk_score'] = df.apply(calculate_risk_score, axis=1)\n",
        "\n",
        "    # Encoding and Scaling\n",
        "    le = LabelEncoder()\n",
        "    df['sex_encoded'] = le.fit_transform(df['sex'])\n",
        "    df['smoker_encoded'] = le.fit_transform(df['smoker'])\n",
        "\n",
        "    df = pd.get_dummies(df, columns=['region', 'age_group', 'bmi_class'], drop_first=True)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    numeric_features = ['age', 'bmi', 'age_squared', 'smoker_bmi_risk', 'age_bmi_risk']\n",
        "    df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
        "\n",
        "    # Final Features\n",
        "    keep_columns = [\n",
        "        'age', 'age_squared', 'sex_encoded', 'bmi', 'children',\n",
        "        'smoker_encoded', 'is_overweight', 'smoker_bmi_risk',\n",
        "        'age_bmi_risk', 'risk_score'\n",
        "    ]\n",
        "    encoded_columns = [col for col in df.columns if col.startswith('region_') or\n",
        "                       col.startswith('age_group_') or col.startswith('bmi_class_')]\n",
        "\n",
        "    df_processed = df[keep_columns + encoded_columns + ['charges']]\n",
        "\n",
        "    return df_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_processed = prepare_features_for_modeling(df)\n",
        "\n",
        "# View ready-to-model features\n",
        "print(df_processed.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Encoding categorical variables:**\n",
        "* Convert categorical variables into numerical format using techniques like one-hot encoding or label encoding.\n",
        "* Drop original categorical columns after encoding to avoid redundancy.\n",
        "  \n",
        "**Numerical transformations:**\n",
        "* Apply scaling to numerical features to better perform in linear models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Find correlation between new features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute correlation matrix for new features (excluding 'charges')\n",
        "new_features = [\n",
        "    'age', 'age_squared', 'sex_encoded', 'bmi', 'children',\n",
        "    'smoker_encoded', 'is_overweight', 'smoker_bmi_risk',\n",
        "    'age_bmi_risk', 'risk_score'\n",
        "]\n",
        "corr_matrix = df_processed[new_features].corr()\n",
        "\n",
        "# Plot the correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Engineered Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/engineered', exist_ok=True)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "df_processed.to_csv('outputs/datasets/engineered/insurance_engineered.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions and Next Steps\n",
        "\n",
        "## Conclusions\n",
        "* We have successfully engineered new features from the existing dataset.\n",
        "\n",
        "# Next Steps\n",
        "* We can now proceed to model training and evaluation using the enhanced dataset."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
