{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1134373",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff49c52e",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "Predict medical insurance charges using customer profile information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd4cbf",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "- Processed customer dataset with feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb40a3",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "- Trained ML regression model.\n",
    "- Feature importance ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e915f7",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ddf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5d8a35",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d0bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba0828",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a39845",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c450640f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec5b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df6efcc",
   "metadata": {},
   "source": [
    "# Load Engineered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc8355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_path = 'outputs/datasets/engineered/insurance_engineered.csv'\n",
    "df = pd.read_csv(df_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e946faf",
   "metadata": {},
   "source": [
    "Stop displaying warnings messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67840326",
   "metadata": {},
   "source": [
    "# ML Pipeline with all data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01ea052",
   "metadata": {},
   "source": [
    "Since we already done the feature engineering in the previous notebook, we can direclty create the ML pipeline with all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80aabb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Feature Engineering\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "def FullPipeline(model):\n",
    "    return Pipeline([\n",
    "        ('correlation_filter', SmartCorrelatedSelection(\n",
    "            method='pearson',\n",
    "            threshold=0.8,\n",
    "            selection_method='variance')),\n",
    "        ('model', model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b56975",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14285814",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db358a50",
   "metadata": {},
   "source": [
    "**Hyperparameter Optimisation**\n",
    "\n",
    "This is the process of tuning the hyperparameters of a machine learning model to improve its performance. It involves searching for the best combination of hyperparameters that yield the highest performance on a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb09d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class HyperparameterOptimizationSearch(BaseEstimator):\n",
    "    def __init__(self, models, params):\n",
    "        \"\"\"\n",
    "        models: dict of {model_name: estimator}\n",
    "        params: dict of {model_name: param_grid}\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=5, n_jobs=-1, verbose=1, scoring=None):\n",
    "        for model_name, model in self.models.items():\n",
    "            print(f\"\\nRunning GridSearchCV for {model_name}\\n\")\n",
    "            \n",
    "            # Wrap model in your pipeline\n",
    "            pipeline = FullPipeline(model)\n",
    "\n",
    "            # Get parameters\n",
    "            param_grid = self.params[model_name]\n",
    "\n",
    "            # Grid search\n",
    "            gs = GridSearchCV(\n",
    "                estimator=pipeline,\n",
    "                param_grid=param_grid,\n",
    "                cv=cv,\n",
    "                n_jobs=n_jobs,\n",
    "                verbose=verbose,\n",
    "                scoring=scoring,\n",
    "                return_train_score=True\n",
    "            )\n",
    "\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[model_name] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(name, scores, params):\n",
    "            return pd.Series({\n",
    "                'estimator': name,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "                **params\n",
    "            })\n",
    "\n",
    "        rows = []\n",
    "        for name, gs in self.grid_searches.items():\n",
    "            params_list = gs.cv_results_['params']\n",
    "            splits = [gs.cv_results_[f'split{i}_test_score'] for i in range(gs.cv)]\n",
    "            all_scores = np.vstack(splits).T  # shape: (n_candidates, n_splits)\n",
    "\n",
    "            for p, s in zip(params_list, all_scores):\n",
    "                rows.append(row(name, s, p))\n",
    "\n",
    "        df = pd.DataFrame(rows).sort_values(by=sort_by, ascending=False)\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        return df[columns + [c for c in df.columns if c not in columns]], self.grid_searches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8501bb",
   "metadata": {},
   "source": [
    "## Split Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5cd78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features (X) and Target (y)\n",
    "X = df.drop(columns=['charges', 'charges_transformed'])\n",
    "y = df['charges_transformed']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=2\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}  y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}  y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b93e7e",
   "metadata": {},
   "source": [
    "## Grid Search CV - Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "models_quick_search = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    \"LinearRegression\": {},\n",
    "    \"DecisionTreeRegressor\": {\n",
    "        'model__max_depth': [None, 10, 20],\n",
    "        'model__min_samples_split': [2, 5],\n",
    "        'model__min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    \"RandomForestRegressor\": {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [None, 10, 20],\n",
    "        'model__min_samples_split': [2, 5],\n",
    "        'model__min_samples_leaf': [1, 2],\n",
    "        'model__bootstrap': [True]\n",
    "    },\n",
    "    \"GradientBoostingRegressor\": {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__learning_rate': [0.1, 0.2],\n",
    "        'model__max_depth': [3, 5],\n",
    "        'model__subsample': [0.8, 1.0],\n",
    "        'model__min_samples_split': [2, 5],\n",
    "        'model__min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    \"XGBRegressor\": {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__learning_rate': [0.1, 0.2],\n",
    "        'model__max_depth': [3, 5],\n",
    "        'model__subsample': [0.8, 1.0],\n",
    "        'model__colsample_bytree': [0.8, 1.0]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e076d",
   "metadata": {},
   "source": [
    "**Run Grid Search CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5bdd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "search = HyperparameterOptimizationSearch(\n",
    "    models=models_quick_search,\n",
    "    params=params_quick_search\n",
    ")\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c3148",
   "metadata": {},
   "source": [
    "Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeabbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "print(grid_search_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b302eda",
   "metadata": {},
   "source": [
    "**Evaluate the Best Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb272ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "best_model = grid_search_summary.iloc[0]['estimator']\n",
    "print(\"Best Model:\", best_model)\n",
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "\n",
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9eacf0",
   "metadata": {},
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f18ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search_pipelines[best_model].best_params_\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472ef62",
   "metadata": {},
   "source": [
    "The best clf pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b3bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
    "pipeline_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c5025",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_clf.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc7b99",
   "metadata": {},
   "source": [
    "With these strong evaluation scores, you are already in excellent shape and an extensive search is not going to be necessary.\n",
    "\n",
    "- High R² on test set (0.847) \n",
    "- Low gap between train/test scores — not overfitting\n",
    "- Low error metrics — strong predictions\n",
    "- Stable RMSE on train/test — very balanced model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158a6892",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e987c3dd",
   "metadata": {},
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the model from the pipeline\n",
    "xgb_model = pipeline_clf.named_steps['model']\n",
    "# Transform training set using the pipeline up to the model\n",
    "X_transformed = pipeline_clf[:-1].transform(X_train)\n",
    "\n",
    "# Get feature names from original DataFrame\n",
    "feature_names = X_train.columns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get importance values\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df, x='Importance', y='Feature', palette='viridis')\n",
    "plt.title('Feature Importance - XGBRegressor')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e61574a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b9fb21",
   "metadata": {},
   "source": [
    "## Evaluate Pipeline on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, pipeline_clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3c6ea",
   "metadata": {},
   "source": [
    "We used R2 Score, MAE and RMSE to evaluate the model performance, since Confusion Matrix and Accuracy are not suitable for regression problems.\n",
    "\n",
    "**Evaluation Conclusion**\n",
    "\n",
    "The XGBRegressor demonstrates strong predictive performance and generalization capability in estimating medical insurance costs. Its test set R² score of 0.847 indicates that the model explains approximately 85% of the variance in insurance charges for unseen data, which is excellent for a real-world regression task. Low and consistent error across training and test sets shows good generalization with minimal overfitting. Feature importance analysis confirms which variables most influence the cost, helping the business better understand risk drivers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a3513f",
   "metadata": {},
   "source": [
    "# Push files to Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29991d5",
   "metadata": {},
   "source": [
    "We will generate the following file\n",
    "* Train set\n",
    "* Test set\n",
    "* Data cleaning and Feature Engineering pipeline\n",
    "* Modeling pipeline\n",
    "* features importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "version = \"v2\"\n",
    "file_path = f\"outputs/ml_pipelines/{version}\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(file_path)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcede993",
   "metadata": {},
   "source": [
    "## Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa85a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d4d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7003716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de306084",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a98fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58479825",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b3ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2523f5",
   "metadata": {},
   "source": [
    "## ML Pipelines: Feature Engineering and Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3448b1ea",
   "metadata": {},
   "source": [
    "Pipeline responsible for Feature Scaling, and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0664112",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b84d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=pipeline_clf ,\n",
    "            filename=f\"{file_path}/clf_pipeline_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "y_transformed = pt.fit_transform(df[['charges']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eca66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pt, f\"{file_path}/power_transformer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21d19ee",
   "metadata": {},
   "source": [
    "## Feature Importance Plot and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb6f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df, x='Importance', y='Feature', palette='viridis')\n",
    "plt.title('Feature Importance - XGBRegressor')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to PNG\n",
    "plt.savefig(f\"{file_path}/feature_importance_xgb.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec5af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df.to_csv(f\"{file_path}/feature_importance_xgb.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
