{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1134373",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff49c52e",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "Predict medical insurance charges using customer profile information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd4cbf",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "- Processed customer dataset with feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb40a3",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "- Trained ML regression model.\n",
    "- Feature importance ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e915f7",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ddf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5d8a35",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d0bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba0828",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a39845",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c450640f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df6efcc",
   "metadata": {},
   "source": [
    "# Load Engineered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc8355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_path = 'outputs/datasets/cleaned/insurance_cleaned.csv'\n",
    "df = pd.read_csv(df_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d55f72",
   "metadata": {},
   "source": [
    "Remove warning messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b83e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8597a53",
   "metadata": {},
   "source": [
    "## Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca20e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['charges'], axis=1),\n",
    "                                                    df['charges'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0,\n",
    "                                                   )\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dacd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{X_test.head()}\\n\\n {X_train.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc41f30",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67840326",
   "metadata": {},
   "source": [
    "# ML Pipeline for Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01ea052",
   "metadata": {},
   "source": [
    "Based on the last notebook, we will create our ML pipeline for data cleaning and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80aabb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Feature Engineering\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "\n",
    "def PipelineDataCleaningAndFeatureEngineering():\n",
    "    categorical_vars = ['sex', 'smoker', 'region']\n",
    "    numerical_vars = ['age', 'bmi']\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('ordinal_encoder', OrdinalEncoder(encoding_method='arbitrary',\n",
    "                                           variables=categorical_vars)),\n",
    "        ('scaler', SklearnTransformerWrapper(transformer=StandardScaler(),\n",
    "                                             variables=numerical_vars))\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "PipelineDataCleaningAndFeatureEngineering()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432d8b2f",
   "metadata": {},
   "source": [
    "**Fit Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\n",
    "\n",
    "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train)\n",
    "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0e75ee",
   "metadata": {},
   "source": [
    "Check if the pipeline does the feature engineering correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8731f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{X_test.head()}\\n\\n {X_train.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125e8373",
   "metadata": {},
   "source": [
    "# ML Pipeline for Modelling and Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec1bd09",
   "metadata": {},
   "source": [
    "- **SmartCorrelation:** removes features with high correlation to avoid multicollinearity.\n",
    "- **model:** the ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feat Selection\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "def PipelineClf(model):\n",
    "    return Pipeline([\n",
    "        ('correlation_filter', SmartCorrelatedSelection(\n",
    "            method='pearson',\n",
    "            threshold=0.8,\n",
    "            selection_method='variance')),\n",
    "        ('model', model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b56975",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14285814",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db358a50",
   "metadata": {},
   "source": [
    "**Hyperparameter Optimisation**\n",
    "\n",
    "This is the process of tuning the hyperparameters of a machine learning model to improve its performance. It involves searching for the best combination of hyperparameters that yield the highest performance on a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb09d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "    \"\"\"\n",
    "    Custom class provided by CI\n",
    "    \"\"\"\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "\n",
    "            model = PipelineClf(self.models[key])\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, )\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b93e7e",
   "metadata": {},
   "source": [
    "## Grid Search CV - Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "models_quick_search = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    \"LinearRegression\": {},\n",
    "    \"DecisionTreeRegressor\": {\n",
    "        'model__max_depth': [None, 10, 20],\n",
    "        'model__min_samples_split': [2, 5],\n",
    "        'model__min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    \"RandomForestRegressor\": {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [None, 10, 20],\n",
    "        'model__min_samples_split': [2, 5],\n",
    "        'model__min_samples_leaf': [1, 2],\n",
    "        'model__bootstrap': [True]\n",
    "    },\n",
    "    \"GradientBoostingRegressor\": {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__learning_rate': [0.1, 0.2],\n",
    "        'model__max_depth': [3, 5],\n",
    "        'model__subsample': [0.8, 1.0],\n",
    "        'model__min_samples_split': [2, 5],\n",
    "        'model__min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    \"XGBRegressor\": {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__learning_rate': [0.1, 0.2],\n",
    "        'model__max_depth': [3, 5],\n",
    "        'model__subsample': [0.8, 1.0],\n",
    "        'model__colsample_bytree': [0.8, 1.0]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e076d",
   "metadata": {},
   "source": [
    "**Run Grid Search CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5bdd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "search = HyperparameterOptimizationSearch(\n",
    "    models=models_quick_search,\n",
    "    params=params_quick_search\n",
    ")\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c3148",
   "metadata": {},
   "source": [
    "Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeabbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "print(grid_search_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b302eda",
   "metadata": {},
   "source": [
    "**Evaluate the Best Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb272ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "best_model = grid_search_summary.iloc[0]['estimator']\n",
    "print(\"Best Model:\", best_model)\n",
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "\n",
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9eacf0",
   "metadata": {},
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f18ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search_pipelines[best_model].best_params_\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472ef62",
   "metadata": {},
   "source": [
    "The best clf pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b3bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
    "pipeline_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c5025",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_clf.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc7b99",
   "metadata": {},
   "source": [
    "The XGBRegressor model has demonstrated strong predictive performance on both the training and test datasets.\n",
    "- **R² Score: 0.891:** The model explains 89.1% of the variance in insurance costs on the training data, indicating a strong fit. \n",
    "- Low gap between train/test scores — not overfitting\n",
    "- Low error metrics — strong predictions\n",
    "- Stable RMSE on train/test — very balanced model\n",
    "\n",
    "XGBRegressor is an optimal choice for this regression task based on both accuracy and stability.With these strong evaluation scores, you are already in excellent shape and an extensive search is not going to be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158a6892",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e987c3dd",
   "metadata": {},
   "source": [
    "## Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transformed feature matrix\n",
    "X_transformed = pipeline_clf[:-1].transform(X_train)\n",
    "\n",
    "# Get feature mask from correlation filter\n",
    "model_selector = pipeline_clf.named_steps['correlation_filter']\n",
    "selected_mask = model_selector.get_support()\n",
    "\n",
    "# Apply mask to original feature names\n",
    "all_features = X_train.columns\n",
    "selected_features = all_features[selected_mask]\n",
    "\n",
    "# Get feature importances\n",
    "model = pipeline_clf.named_steps['model']\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Create importance DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a5716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df, x='Importance', y='Feature', palette='viridis')\n",
    "plt.title(f'Feature Importance - {model.__class__.__name__}')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e61574a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b9fb21",
   "metadata": {},
   "source": [
    "## Evaluate Pipeline on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, pipeline_clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3c6ea",
   "metadata": {},
   "source": [
    "We used R2 Score, MAE and RMSE to evaluate the model performance, since Confusion Matrix and Accuracy are not suitable for regression problems.\n",
    "\n",
    "**Evaluation Conclusion**\n",
    "\n",
    "The XGBRegressor demonstrates strong predictive performance and generalization capability in estimating medical insurance costs. Its test set R² score of 0.891 indicates that the model explains approximately 89% of the variance in insurance charges for unseen data, which is excellent for a real-world regression task. Low and consistent error across training and test sets shows good generalization with minimal overfitting. Feature importance analysis confirms which variables most influence the cost, helping the business better understand risk drivers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a3513f",
   "metadata": {},
   "source": [
    "# Push files to Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29991d5",
   "metadata": {},
   "source": [
    "We will generate the following file\n",
    "* Train set\n",
    "* Test set\n",
    "* Data cleaning and Feature Engineering pipeline\n",
    "* Modeling pipeline\n",
    "* features importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "version = \"v1\"\n",
    "file_path = f\"outputs/ml_pipelines/{version}\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(file_path)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcede993",
   "metadata": {},
   "source": [
    "## Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa85a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d4d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7003716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de306084",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a98fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58479825",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b3ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2523f5",
   "metadata": {},
   "source": [
    "## ML Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcef4aaf",
   "metadata": {},
   "source": [
    "### Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3b8999",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipeline_data_cleaning_feat_eng, \n",
    "            f\"{file_path}/pipeline_data_cleaning_feat_eng.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3448b1ea",
   "metadata": {},
   "source": [
    "Pipeline responsible to transform the predicted target back to the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eca66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "joblib.dump(pt, f\"{file_path}/power_transformer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14866281",
   "metadata": {},
   "source": [
    "### Modeling Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipeline_clf, f\"{file_path}/clf_pipeline_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21d19ee",
   "metadata": {},
   "source": [
    "## Feature Importance Plot and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb6f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df, x='Importance', y='Feature', palette='viridis')\n",
    "plt.title('Feature Importance - XGBRegressor')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to PNG\n",
    "plt.savefig(f\"{file_path}/feature_importance_xgb.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec5af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df.to_csv(f\"{file_path}/feature_importance_xgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945952ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f733e",
   "metadata": {},
   "source": [
    "Testing the prediction on a single raw value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de45b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(1, random_state=421)\n",
    "print(\"Sample Input Data:\\n\", df_sample)\n",
    "\n",
    "predict_sample = df_sample.drop(['charges'], axis=1)\n",
    "\n",
    "# Transform using the already fitted pipeline\n",
    "fe_df = pipeline_data_cleaning_feat_eng.transform(predict_sample)\n",
    "fe_df = pd.DataFrame(fe_df, columns=predict_sample.columns, index=predict_sample.index)\n",
    "print(\"Transformed Sample Input Data:\\n\", fe_df)\n",
    "\n",
    "# Predict using the full pipeline\n",
    "predicted_charges = pipeline_clf.predict(fe_df)\n",
    "print(\"Predicted Charges:\\n\", predicted_charges)\n",
    "print(\"Actual Charges:\\n\", df_sample['charges'].values)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
