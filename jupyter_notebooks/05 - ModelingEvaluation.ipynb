{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modeling and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fit and evaluate a model pipeline to predict chargers\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Engineered features 'output/datasets/engineered/insurance_engineered.csv' \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Model pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Engineered Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_path = 'outputs/datasets/engineered/insurance_engineered.csv'\n",
        "df_processed = pd.read_csv(df_path)\n",
        "df_processed.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Disable warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Train/Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split features and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Features (X) and Target (y)\n",
        "X = df_processed.drop('charges', axis=1)\n",
        "y = df_processed['charges']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train/Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=2)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}  y_train shape: {y_train.shape}\"\n",
        "      f\"\\nX_test shape: {X_test.shape}  y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define Hyperparameters and Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "models = {\n",
        "    \"Linear Regression\": {\n",
        "        \"model\": LinearRegression(),\n",
        "        \"params\": {\n",
        "            \"fit_intercept\": [True, False],\n",
        "            \"normalize\": [False]\n",
        "        }\n",
        "    },\n",
        "    \"Ridge Regression\": {\n",
        "        \"model\": Ridge(),\n",
        "        \"params\": {\n",
        "            \"alpha\": [0.01, 0.1, 1, 10, 100],\n",
        "            \"fit_intercept\": [True, False]\n",
        "        }\n",
        "    },\n",
        "    \"Random Forest\": {\n",
        "        \"model\": RandomForestRegressor(random_state=2),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200],\n",
        "            \"max_depth\": [None, 10, 20],\n",
        "            \"min_samples_split\": [2, 5],\n",
        "        }\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        \"model\": XGBRegressor(objective='reg:squarederror', random_state=2),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 200],\n",
        "            \"max_depth\": [3, 6],\n",
        "            \"learning_rate\": [0.01, 0.1],\n",
        "            \"subsample\": [0.8, 1.0]\n",
        "        }\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train and Evaluate All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model_name = None\n",
        "best_model_obj = None\n",
        "best_score = -np.inf \n",
        "\n",
        "results = []\n",
        "\n",
        "for name, cfg in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    if name == \"Linear Regression\" and \"normalize\" in cfg[\"params\"]:\n",
        "        del cfg[\"params\"][\"normalize\"]\n",
        "    \n",
        "    grid = GridSearchCV(cfg[\"model\"], cfg[\"params\"], cv=5, scoring=\"r2\", n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    best_model = grid.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    if r2 > best_score:\n",
        "        best_score = r2\n",
        "        best_model_name = name\n",
        "        best_model_obj = best_model\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"RÂ²\": round(r2, 3),\n",
        "        \"RMSE\": round(rmse, 2),\n",
        "        \"MAE\": round(mae, 2)\n",
        "    })\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show Results Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_tree_model_features(model, feature_names, title):\n",
        "    importances = model.feature_importances_\n",
        "    sorted_idx = np.argsort(importances)[::-1]\n",
        "    top_features = [feature_names[i] for i in sorted_idx]\n",
        "    top_importances = importances[sorted_idx]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(top_features, top_importances)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Feature Importance\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def plot_linear_model_coefficients(model, feature_names, title):\n",
        "    coefs = model.coef_\n",
        "    sorted_idx = np.argsort(np.abs(coefs))[::-1]\n",
        "    top_features = [feature_names[i] for i in sorted_idx]\n",
        "    top_coefs = coefs[sorted_idx]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(top_features, top_coefs)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Coefficient Value\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def get_feature_importance_df(model, feature_names, model_type):\n",
        "    if model_type in [\"Random Forest\", \"XGBoost\"]:\n",
        "        values = model.feature_importances_\n",
        "    elif model_type in [\"Linear Regression\", \"Ridge Regression\"]:\n",
        "        values = model.coef_\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model type for feature importance extraction.\")\n",
        "\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': values\n",
        "    })\n",
        "\n",
        "    importance_df['Abs_Importance'] = importance_df['Importance'].abs()\n",
        "    importance_df.sort_values(by='Abs_Importance', ascending=False, inplace=True)\n",
        "    importance_df.drop(columns='Abs_Importance', inplace=True)\n",
        "    importance_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    return importance_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "results_df.sort_values(by=\"RÂ²\", ascending=False, inplace=True)\n",
        "results_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"Model Evaluation Results:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* GridSearchCV uses 5-fold cross-validation by default\n",
        "* We tested 4 models:\n",
        "  * Linear Regression\n",
        "  * Random Forest Regressor\n",
        "  * Gradient Boosting Regressor\n",
        "  * XGBoost Regressor\n",
        "* All the models perfomed good, but the best model is XGBoost Regressor with a R2 score of 0.87\n",
        "\n",
        "## Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_names = X_train.columns.tolist()\n",
        "\n",
        "# Get and display the importance table\n",
        "importance_df = get_feature_importance_df(best_model_obj, feature_names, best_model_name)\n",
        "print(f\"\\nFeature Importance Ranking for {best_model_name}:\\n\")\n",
        "print(importance_df.to_string(index=True))\n",
        "\n",
        "plot_tree_model_features(best_model_obj, feature_names, f\"{best_model_name} - Feature Importance\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Refit pipeline with the Best Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The feature importance table and plot shows the most important features for the model. We can see that the `risk_score, smoker_bmi_risk, smoker_encoded, age, bmi, children, age_bmi_risk` are the most important features for the model. However, we can see that the `age_squared, is_overweight, age_group_*, bmi_class_*, most region_*, sex_encoded` are not important features for the model. This means that we can remove these features from the dataset and retrain the model to see if we can improve the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_to_drop = [\"age_squared\", \"is_overweight\", \n",
        "    \"age_group_Senior\", \"bmi_class_Obese\", \"age_group_Middle-aged\",\n",
        "    \"region_northwest\", \"region_southeast\", \n",
        "    \"age_group_Adult\", \"sex_encoded\",\n",
        "    \"bmi_class_Normal\", \"bmi_class_Overweight\", \"region_southwest\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "# Drop low-importance features\n",
        "X_reduced = X.drop(columns=[col for col in features_to_drop if col in X.columns])\n",
        "\n",
        "# Re-split with new feature set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_red, X_test_red, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Retrain the same model (use best_model_obj which is XGBoost)\n",
        "best_model_obj.fit(X_train_red, y_train)\n",
        "\n",
        "# Predict with reduced features\n",
        "y_pred_red = best_model_obj.predict(X_test_red)\n",
        "\n",
        "# Evaluate\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "r2_red = r2_score(y_test, y_pred_red)\n",
        "rmse_red = np.sqrt(mean_squared_error(y_test, y_pred_red))\n",
        "mae_red = mean_absolute_error(y_test, y_pred_red)\n",
        "\n",
        "print(\"Evaluation After Dropping Low-Importance Features:\")\n",
        "print(f\"RÂ² Score:  {r2_red:.3f}\")\n",
        "print(f\"RMSE:      ${rmse_red:.2f}\")\n",
        "print(f\"MAE:       ${mae_red:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After retraining the model with the reduced dataset, we can see that the model performance had a slight improvement, with a R2 score of 0.874 (previusly 0.870). This means that the model is able to explain 87.4% of the variance in the target variable, which is a good result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assess Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_names = X_reduced.columns.tolist()\n",
        "\n",
        "# Get and display the importance table\n",
        "importance_df = get_feature_importance_df(best_model_obj, feature_names, best_model_name)\n",
        "print(f\"\\nFeature Importance Ranking for {best_model_name}:\\n\")\n",
        "print(importance_df.to_string(index=True))\n",
        "\n",
        "plot_tree_model_features(best_model_obj, feature_names, f\"{best_model_name} - Feature Importance\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def final_feature_engineering(df):  # your full engineering function\n",
        "\n",
        "    # Drop low-importance features\n",
        "    drop_cols = [\n",
        "        \"age_squared\", \"is_overweight\", \n",
        "        \"age_group_Senior\", \"bmi_class_Obese\", \"age_group_Middle-aged\",\n",
        "        \"region_northwest\", \"region_southeast\", \n",
        "        \"age_group_Adult\", \"sex_encoded\",\n",
        "        \"bmi_class_Normal\", \"bmi_class_Overweight\", \"region_southwest\"\n",
        "    ]\n",
        "    df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
        "    \n",
        "    # Separate X and y\n",
        "    X = df.drop(columns=[\"charges\"])\n",
        "    y = df[\"charges\"]\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class FeatureEngineeringWrapper(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self  # no fitting needed\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_transformed, _ = final_feature_engineering(X)\n",
        "        return X_transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Initialize pipeline\n",
        "final_pipeline = Pipeline([\n",
        "    ('feature_engineering', FeatureEngineeringWrapper()),\n",
        "    ('model', XGBRegressor(objective='reg:squarederror', random_state=42, \n",
        "                           n_estimators=200, max_depth=6, learning_rate=0.1, subsample=1.0))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_, y_all = final_feature_engineering(df_processed)\n",
        "final_pipeline.fit(df_processed, y_all)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have a full reusable pipeline that can be used to transform the data and train the model. We can use this pipeline to transform new data and make predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "version = 'v1'\n",
        "file_path = f\"outputs/ml_pipeline/predict_insurance_cost/{version}\"\n",
        "\n",
        "try:\n",
        "    os.makedirs(name=file_path, exist_ok=True)\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save train/test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save train/test sets as CSV\n",
        "X_train_red.to_csv(f\"{file_path}/X_train.csv\", index=False)\n",
        "X_test_red.to_csv(f\"{file_path}/X_test.csv\", index=False)\n",
        "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)\n",
        "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "import joblib\n",
        "\n",
        "# Define your feature engineering as a FunctionTransformer\n",
        "def manual_feature_engineering(X):\n",
        "    return X.drop(columns=features_to_drop)\n",
        "\n",
        "feature_pipeline = Pipeline(steps=[\n",
        "    ('custom_features', FunctionTransformer(manual_feature_engineering, validate=False))\n",
        "])\n",
        "\n",
        "# Save pipeline\n",
        "joblib.dump(feature_pipeline, f\"{file_path}/feature_pipeline.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save feature importance plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_tree_feature_importance_plot(model, feature_names, model_name, file_path):\n",
        "    importances = model.feature_importances_\n",
        "    sorted_idx = np.argsort(importances)[::-1]\n",
        "    top_features = [feature_names[i] for i in sorted_idx]\n",
        "    top_importances = importances[sorted_idx]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(top_features, top_importances)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.title(f\"{model_name} - Feature Importance\")\n",
        "    plt.xlabel(\"Importance\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{file_path}/feature_importance_{model_name}.png\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the appropriate plot\n",
        "save_tree_feature_importance_plot(best_model_obj, X_reduced.columns.tolist(), best_model_name, file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save model pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(final_pipeline, f\"{file_path}/clf_pipeline.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have successfully built a model pipeline to predict insurance charges using the engineered features. The best model was the XGBoost Regressor, which achieved a R2 score of 0.874. We also assessed the feature importance and retrained the model with the most important features, achieving a slight improvement in performance. The final model pipeline is ready for use in making predictions on new data."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
